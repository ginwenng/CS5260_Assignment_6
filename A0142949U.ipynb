{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-V7LyPuI4v9",
        "outputId": "bd2a36a0-9b54-4897-def5-0c79649195d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting colossalai\n",
            "  Downloading colossalai-0.1.1.tar.gz (256 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▎                              | 10 kB 19.0 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 20 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 30 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 40 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 51 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 61 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 71 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 81 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 92 kB 5.9 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 102 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 112 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 122 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 133 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 143 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 153 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 163 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 174 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 184 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 194 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 204 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 215 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 225 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 235 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 245 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 256 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 256 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.8 in /usr/local/lib/python3.7/dist-packages (from colossalai) (1.10.0+cu111)\n",
            "Requirement already satisfied: torchvision>=0.9 in /usr/local/lib/python3.7/dist-packages (from colossalai) (0.11.1+cu111)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from colossalai) (1.21.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from colossalai) (4.63.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from colossalai) (5.4.8)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from colossalai) (2.8.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from colossalai) (21.3)\n",
            "Collecting pre-commit\n",
            "  Downloading pre_commit-2.17.0-py2.py3-none-any.whl (195 kB)\n",
            "\u001b[K     |████████████████████████████████| 195 kB 54.5 MB/s \n",
            "\u001b[?25hCollecting rich\n",
            "  Downloading rich-12.0.1-py3-none-any.whl (224 kB)\n",
            "\u001b[K     |████████████████████████████████| 224 kB 58.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.8->colossalai) (3.10.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.9->colossalai) (7.1.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->colossalai) (3.0.7)\n",
            "Collecting identify>=1.0.0\n",
            "  Downloading identify-2.4.12-py2.py3-none-any.whl (98 kB)\n",
            "\u001b[K     |████████████████████████████████| 98 kB 7.1 MB/s \n",
            "\u001b[?25hCollecting nodeenv>=0.11.1\n",
            "  Downloading nodeenv-1.6.0-py2.py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from pre-commit->colossalai) (4.11.3)\n",
            "Collecting toml\n",
            "  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
            "Collecting cfgv>=2.0.0\n",
            "  Downloading cfgv-3.3.1-py2.py3-none-any.whl (7.3 kB)\n",
            "Collecting virtualenv>=20.0.8\n",
            "  Downloading virtualenv-20.14.0-py2.py3-none-any.whl (8.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.8 MB 50.9 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 67.3 MB/s \n",
            "\u001b[?25hCollecting distlib<1,>=0.3.1\n",
            "  Downloading distlib-0.3.4-py2.py3-none-any.whl (461 kB)\n",
            "\u001b[K     |████████████████████████████████| 461 kB 73.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six<2,>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from virtualenv>=20.0.8->pre-commit->colossalai) (1.15.0)\n",
            "Requirement already satisfied: filelock<4,>=3.2 in /usr/local/lib/python3.7/dist-packages (from virtualenv>=20.0.8->pre-commit->colossalai) (3.6.0)\n",
            "Collecting platformdirs<3,>=2\n",
            "  Downloading platformdirs-2.5.1-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->pre-commit->colossalai) (3.7.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from rich->colossalai) (2.6.1)\n",
            "Collecting commonmark<0.10.0,>=0.9.0\n",
            "  Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n",
            "\u001b[K     |████████████████████████████████| 51 kB 4.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->colossalai) (1.35.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->colossalai) (1.0.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->colossalai) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->colossalai) (1.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->colossalai) (3.3.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->colossalai) (57.4.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->colossalai) (3.17.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->colossalai) (0.6.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->colossalai) (0.37.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->colossalai) (1.44.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->colossalai) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->colossalai) (0.4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->colossalai) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->colossalai) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->colossalai) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->colossalai) (1.3.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->colossalai) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->colossalai) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->colossalai) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->colossalai) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->colossalai) (2021.10.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->colossalai) (3.2.0)\n",
            "Building wheels for collected packages: colossalai\n",
            "  Building wheel for colossalai (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for colossalai: filename=colossalai-0.1.1-py3-none-any.whl size=284561 sha256=28f952b6509b0c169274e0cc812c31101ebc096962652b583e178fb51cddfce0\n",
            "  Stored in directory: /root/.cache/pip/wheels/b2/7a/a1/62e6c3722e0305168510c395571827390fc52b93539ab5a196\n",
            "Successfully built colossalai\n",
            "Installing collected packages: platformdirs, distlib, virtualenv, toml, pyyaml, nodeenv, identify, commonmark, cfgv, rich, pre-commit, colossalai\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed cfgv-3.3.1 colossalai-0.1.1 commonmark-0.9.1 distlib-0.3.4 identify-2.4.12 nodeenv-1.6.0 platformdirs-2.5.1 pre-commit-2.17.0 pyyaml-6.0 rich-12.0.1 toml-0.10.2 virtualenv-20.14.0\n"
          ]
        }
      ],
      "source": [
        "!pip3 install colossalai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install pytorch-lamb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EnYmq6l2gctr",
        "outputId": "c8e10e17-0b31-41b6-8a65-2942b2b71edf"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-lamb\n",
            "  Downloading pytorch_lamb-1.0.0-py3-none-any.whl (4.4 kB)\n",
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.5-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[K     |████████████████████████████████| 125 kB 4.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch-lamb) (4.63.0)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lamb) (1.10.0+cu111)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from pytorch-lamb) (0.11.1+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.1->pytorch-lamb) (3.10.0.2)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX->pytorch-lamb) (3.17.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorboardX->pytorch-lamb) (1.21.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tensorboardX->pytorch-lamb) (1.15.0)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->pytorch-lamb) (7.1.2)\n",
            "Installing collected packages: tensorboardX, pytorch-lamb\n",
            "Successfully installed pytorch-lamb-1.0.0 tensorboardX-2.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 show torch\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RzetnwUYKMzn",
        "outputId": "73b6e761-b2d2-4f8f-df8e-eb2958e849e6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: torch\n",
            "Version: 1.10.0+cu111\n",
            "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n",
            "Home-page: https://pytorch.org/\n",
            "Author: PyTorch Team\n",
            "Author-email: packages@pytorch.org\n",
            "License: BSD-3\n",
            "Location: /usr/local/lib/python3.7/dist-packages\n",
            "Requires: typing-extensions\n",
            "Required-by: torchvision, torchtext, torchaudio, pytorch-lamb, fastai, colossalai\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch_lamb import Lamb"
      ],
      "metadata": {
        "id": "MfSLl9v9gzQY"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.optim.optimizer import Optimizer, required\n",
        "\n",
        "\n",
        "class LARS(Optimizer):\n",
        "    r\"\"\"Implements layer-wise adaptive rate scaling for SGD.\n",
        "    Args:\n",
        "        params (iterable): iterable of parameters to optimize or dicts defining\n",
        "            parameter groups\n",
        "        lr (float): base learning rate (\\gamma_0)\n",
        "        momentum (float, optional): momentum factor (default: 0) (\"m\")\n",
        "        weight_decay (float, optional): weight decay (L2 penalty) (default: 0)\n",
        "            (\"\\beta\")\n",
        "    Based on Algorithm 1 of the following paper by You, Gitman, and Ginsburg.\n",
        "    Large batch training of convolutional networks with layer-wise adaptive rate scaling. ICLR'18:\n",
        "        https://openreview.net/pdf?id=rJ4uaX2aW\n",
        "    The LARS algorithm can be written as\n",
        "    .. math::\n",
        "            \\begin{aligned}\n",
        "                v_{t+1} & = \\mu * v_{t} + (1.0 - \\mu) * (g_{t} + \\beta * w_{t}), \\\\\n",
        "                w_{t+1} & = w_{t} - lr * ||w_{t}|| / ||v_{t+1}|| * v_{t+1},\n",
        "            \\end{aligned}\n",
        "    where :math:`w`, :math:`g`, :math:`v` and :math:`\\mu` denote the\n",
        "        parameters, gradient, velocity, and momentum respectively.\n",
        "    Example:\n",
        "        >>> optimizer = LARS(model.parameters(), lr=0.1)\n",
        "        >>> optimizer.zero_grad()\n",
        "        >>> loss_fn(model(input), target).backward()\n",
        "        >>> optimizer.step()\n",
        "    \"\"\"\n",
        "    def __init__(self, params, lr=required, momentum=.9,\n",
        "                 weight_decay=.0005, dampening = 0):\n",
        "        if lr is not required and lr < 0.0:\n",
        "            raise ValueError(\"Invalid learning rate: {}\".format(lr))\n",
        "        if momentum < 0.0:\n",
        "            raise ValueError(\"Invalid momentum value: {}\".format(momentum))\n",
        "        if weight_decay < 0.0:\n",
        "            raise ValueError(\"Invalid weight_decay value: {}\"\n",
        "                             .format(weight_decay))\n",
        "        #if eta < 0.0:\n",
        "        #    raise ValueError(\"Invalid eta value:{}\".format(eta))\n",
        "\n",
        "        defaults = dict(lr=lr, momentum = momentum,\n",
        "                        weight_decay = weight_decay,\n",
        "                        dampening = dampening)\n",
        "\n",
        "        super(LARS, self).__init__(params, defaults)\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def step(self, closure=None):\n",
        "        \"\"\"Performs a single optimization step.\n",
        "        Arguments:\n",
        "            closure (callable, optional): A closure that reevaluates the model\n",
        "                and returns the loss.\n",
        "        \"\"\"\n",
        "        loss = None\n",
        "        if closure is not None:\n",
        "            loss = closure()\n",
        "\n",
        "\n",
        "        for group in self.param_groups:\n",
        "            weight_decay = group['weight_decay']\n",
        "            momentum = group['momentum']\n",
        "            lr = group['lr']\n",
        "            dampening = group['dampening']\n",
        "\n",
        "            for p in group['params']:\n",
        "                if p.grad is None:\n",
        "                    continue\n",
        "\n",
        "                param_state = self.state[p]\n",
        "                # gradient\n",
        "                d_p = p.grad.data\n",
        "                weight_norm = torch.norm(p.data)\n",
        "\n",
        "                # update the velocity\n",
        "                if 'momentum_buffer' not in param_state:\n",
        "                    buf = param_state['momentum_buffer'] = torch.zeros_like(p.data)\n",
        "                else:\n",
        "                    buf = param_state['momentum_buffer']\n",
        "                # l2 regularization\n",
        "                if weight_decay != 0:\n",
        "                    d_p.add_(p, alpha=weight_decay)\n",
        "\n",
        "                buf.mul_(momentum).add_(d_p, alpha = 1.0 - dampening)\n",
        "                v_norm = torch.norm(buf)\n",
        "\n",
        "                local_lr = lr * weight_norm / (1e-6 + v_norm)\n",
        "\n",
        "                # Update the weight\n",
        "                p.add_(buf, alpha = -local_lr)\n",
        "\n",
        "\n",
        "        return loss"
      ],
      "metadata": {
        "id": "1it_PrrMoOel"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "-tmXEtii7-7F",
        "outputId": "fabe2d8b-0192-427b-cd09-444769437855"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "If you want to activate cuda mode for MoE, please install with cuda_ext!\n",
            "Colossalai should be built with cuda extension to use the FP16 optimizer\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/autocast_mode.py:141: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-70e045c9f46c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'BATCH_SIZE'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'NUM_EPOCHS'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m \u001b[0mcolossalai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mworld_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'127.0.0.1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1234\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0mlogger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_dist_logger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/colossalai/initialize.py\u001b[0m in \u001b[0;36mlaunch\u001b[0;34m(config, rank, world_size, host, port, backend, local_rank, seed, verbose)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;31m# init default process group\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m     \u001b[0mgpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_global_dist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworld_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;31m# init process groups for different parallel modes from config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/colossalai/context/parallel_context.py\u001b[0m in \u001b[0;36minit_global_dist\u001b[0;34m(self, rank, world_size, backend, host, port)\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0;31m# initialize the default process group\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m         \u001b[0minit_method\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'tcp://{host}:{port}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 303\u001b[0;31m         \u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_process_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworld_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworld_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minit_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;31m# None will give the default global process group for pytorch dist operations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/distributed/distributed_c10d.py\u001b[0m in \u001b[0;36minit_process_group\u001b[0;34m(backend, init_method, timeout, world_size, rank, store, group_name, pg_options)\u001b[0m\n\u001b[1;32m    589\u001b[0m             \u001b[0mpg_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpg_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m             \u001b[0mgroup_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m             \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    592\u001b[0m         )\n\u001b[1;32m    593\u001b[0m         \u001b[0m_update_default_pg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_pg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/distributed/distributed_c10d.py\u001b[0m in \u001b[0;36m_new_process_group_helper\u001b[0;34m(world_size, rank, group_ranks, backend, store, pg_options, group_name, timeout)\u001b[0m\n\u001b[1;32m    717\u001b[0m                 \u001b[0mpg_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m             \u001b[0mpg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mProcessGroupNCCL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix_store\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworld_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpg_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m             \u001b[0;31m# In debug mode and if GLOO is available, wrap in a wrapper PG that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m             \u001b[0;31m# enables enhanced collective checking for debugability.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: ProcessGroupNCCL is only supported with GPUs, no GPUs found!"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "import math\n",
        "import colossalai\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from colossalai.core import global_context as gpc\n",
        "from colossalai.logging import get_dist_logger\n",
        "from colossalai.nn import CosineAnnealingLR\n",
        "from colossalai.nn.metric import Accuracy\n",
        "from colossalai.trainer import Trainer, hooks\n",
        "from colossalai.utils import MultiTimer, get_dataloader\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import MNIST\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "\n",
        "class LeNet5(nn.Module):\n",
        "\n",
        "    def __init__(self, n_classes):\n",
        "        super(LeNet5, self).__init__()\n",
        "\n",
        "        self.feature_extractor = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1),\n",
        "            nn.Tanh(),\n",
        "            nn.AvgPool2d(kernel_size=2),\n",
        "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1),\n",
        "            nn.Tanh(),\n",
        "            nn.AvgPool2d(kernel_size=2),\n",
        "            nn.Conv2d(in_channels=16, out_channels=120, kernel_size=5, stride=1),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(in_features=120, out_features=84),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(in_features=84, out_features=n_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.feature_extractor(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        logits = self.classifier(x)\n",
        "        probs = F.softmax(logits, dim=1)\n",
        "        return logits\n",
        "\n",
        "\n",
        "config = {'BATCH_SIZE':128,'NUM_EPOCHS':30}\n",
        "\n",
        "colossalai.launch(config=config,rank=0,world_size=1,host='127.0.0.1',port=1234)\n",
        "\n",
        "logger = get_dist_logger()\n",
        "\n",
        "# build \n",
        "\n",
        "model = LeNet5(n_classes=10)\n",
        "\n",
        "# build dataloaders\n",
        "train_dataset = MNIST(\n",
        "    root=Path('./tmp/'),\n",
        "    download=True,\n",
        "    transform = transforms.Compose([transforms.Resize((32, 32)),\n",
        "                              transforms.ToTensor()])\n",
        ")\n",
        "\n",
        "test_dataset = MNIST(\n",
        "    root=Path('./tmp/'),\n",
        "    train=False,\n",
        "    transform = transforms.Compose([transforms.Resize((32, 32)),\n",
        "                              transforms.ToTensor()])\n",
        ")\n",
        "\n",
        "train_dataloader = get_dataloader(dataset=train_dataset,\n",
        "                                  shuffle=True,\n",
        "                                  batch_size=gpc.config.BATCH_SIZE,\n",
        "                                  num_workers=1,\n",
        "                                  pin_memory=True,\n",
        "                                  )\n",
        "\n",
        "test_dataloader = get_dataloader(dataset=test_dataset,\n",
        "                                  add_sampler=False,\n",
        "                                  batch_size=gpc.config.BATCH_SIZE,\n",
        "                                  num_workers=1,\n",
        "                                  pin_memory=True,\n",
        "                                  )\n",
        "\n",
        "# build criterion\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# optimizer\n",
        "# optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.1, weight_decay=5e-4)\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr=0.1, weight_decay=5e-4)\n",
        "# optimizer = Lamb(model.parameters(), lr=0.1, weight_decay=5e-4, betas=(.9, .999), adam=True)\n",
        "# optimizer = Lamb(model.parameters(), lr=0.1, weight_decay=5e-4, betas=(.9, .999), adam=False)\n",
        "# optimizer = LARS(model.parameters(), lr=0.1, weight_decay=5e-4)\n",
        "\n",
        "\n",
        "#exponentially increase learning rate from low to high\n",
        "def lrs(batch):\n",
        "    low = math.log2(1e-5)\n",
        "    high = math.log2(10)\n",
        "    return 2**(low+(high-low)*batch/len(train_dataloader)/gpc.config.NUM_EPOCHS)\n",
        "\n",
        "# lr_scheduler\n",
        "# lr_scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lrs)\n",
        "lr_scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, math.log2(10), steps_per_epoch=2, epochs=30)\n",
        "# lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[5, 10, 15, 20, 25])\n",
        "# lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[10, 20])\n",
        "\n",
        "engine, train_dataloader, test_dataloader, _ = colossalai.initialize(model,\n",
        "                                                                      optimizer,\n",
        "                                                                      criterion,\n",
        "                                                                      train_dataloader,\n",
        "                                                                      test_dataloader,\n",
        "                                                                      )\n",
        "# build a timer to measure time\n",
        "timer = MultiTimer()\n",
        "\n",
        "# create a trainer object\n",
        "trainer = Trainer(\n",
        "    engine=engine,\n",
        "    timer=timer,\n",
        "    logger=logger\n",
        ")\n",
        "\n",
        "# define the hooks to attach to the trainer\n",
        "hook_list = [\n",
        "    hooks.LossHook(),\n",
        "    hooks.LRSchedulerHook(lr_scheduler=lr_scheduler, by_epoch=False),\n",
        "    # hooks.AccuracyHook(accuracy_func=Accuracy()),\n",
        "    hooks.LogMetricByEpochHook(logger),\n",
        "    hooks.LogMemoryByEpochHook(logger),\n",
        "    hooks.LogTimingByEpochHook(timer, logger),\n",
        "\n",
        "    # you can uncomment these lines if you wish to use them\n",
        "    hooks.TensorboardHook(log_dir='./tb_logs', ranks=[0]),\n",
        "    # hooks.SaveCheckpointHook(checkpoint_dir='./ckpt')\n",
        "]\n",
        "\n",
        "# start training\n",
        "trainer.fit(\n",
        "    train_dataloader=train_dataloader,\n",
        "    epochs=gpc.config.NUM_EPOCHS,\n",
        "    test_dataloader=test_dataloader,\n",
        "    test_interval=1,\n",
        "    hooks=hook_list,\n",
        "    display_progress=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n32Q0ITyWdBy"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir tb_logs"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "A0142949U.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}